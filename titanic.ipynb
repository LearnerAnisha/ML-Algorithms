{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1 : Understanding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after processing:\n",
      "    PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare\n",
      "0            1         0       3  22.0      1      0   7.2500\n",
      "1            2         1       1  38.0      1      0  71.2833\n",
      "2            3         1       3  26.0      0      0   7.9250\n",
      "3            4         1       1  35.0      1      0  53.1000\n",
      "4            5         0       3  35.0      0      0   8.0500\n",
      "Missing values after processing:\n",
      " PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load the titanic data set\n",
    "data = pd.read_csv(\"/Users/anishagautam/Personal/ML Algorithm/titanic.csv\")\n",
    "\n",
    "#select categorical columns\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# drop all categorical columns except \"survived\"\n",
    "data = data.drop(columns=[col for col in categorical_columns if col!= 'Survived'])\n",
    "\n",
    "# check for missing values\n",
    "missing_info = data.isnull().sum()/ (len(data)*100)\n",
    "\n",
    "# handle missing values\n",
    "for column in data.columns:\n",
    "  if ( missing_info[column] > 10):\n",
    "    data[column].fillna(data[column].mean(),inplace=True)\n",
    "  else:\n",
    "    data.dropna(subset=[column],inplace=True)\n",
    "\n",
    "#display clean data\n",
    "print(f\"Data after processing:\\n {data.head()}\")\n",
    "print(f\"Missing values after processing:\\n {data.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step2 : Creating a Feature Matrix and Label Vector and Splitting Train - Test Split:This"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (500, 6)\n",
      "Shape of X_test (214, 6)\n",
      "Shape of Y_train (500,)\n",
      "Shape of Y_test (214,)\n"
     ]
    }
   ],
   "source": [
    "# Separate inputs (X) and outputs (Y)\n",
    "X = data.drop(columns=['Survived']).values  # Convert features to numpy array\n",
    "Y = data['Survived'].values  # Convert targets to numpy array\n",
    "\n",
    "# Define a function for train-test split from scratch\n",
    "def train_test_split(X, Y, test_size=0.3, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    test_split_size = int(len(X) * test_size)\n",
    "    test_indices = indices[:test_split_size]\n",
    "    train_indices = indices[test_split_size:]\n",
    "    \n",
    "    # Ensure X is sliced correctly for both train and test sets\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    \n",
    "    # Ensure Y is sliced correctly for both train and test sets (1D array)\n",
    "    Y_train, Y_test = Y[train_indices], Y[test_indices]\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, Y_train, X_test, Y_test = train_test_split(X, Y, test_size=0.3)\n",
    "\n",
    "# Output shapes to verify\n",
    "print(\"Shape of X_train: \", X_train.shape)  \n",
    "print(\"Shape of X_test\", X_test.shape)      \n",
    "print(\"Shape of Y_train\", Y_train.shape)   \n",
    "print(\"Shape of Y_test\", Y_test.shape)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step3 : Computing Euclidean Distance Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(point1,point2):\n",
    "  if (point1.shape != point2.shape) :\n",
    "    raise ValueError(\"Points must have same dimension to calculate distance.\")\n",
    "  distance = np.sqrt(np.sum(point1 - point2)**2)\n",
    "  return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step4 : Implementation of core knn algorithm for single query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predict_single(query,X_train,Y_train,k=3):\n",
    "  distance = [euclidean_distance(query,x) for x in X_train]\n",
    "  sorted_indices = np.argsort(distance)\n",
    "  nearest_indices = sorted_indices[:k]\n",
    "  nearest_labels = Y_train[nearest_indices]\n",
    "  prediction = np.bincount(nearest_labels).argmax()\n",
    "  return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Class Labels for All Test Samples - knn predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predict(X_test,X_train,Y_train,k=3):\n",
    "  predictions = [knn_predict_single(x,X_train,Y_train,k) for x in X_test]\n",
    "  return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step5 : Test case for knn algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [0 0 0 0 1]\n",
      "Actual labels:  [0 1 1 1 0]\n",
      "Test case pass successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  # define a test set for the test case\n",
    "  X_test_sample = X_test[:5]\n",
    "  Y_test_sample = Y_test[:5]\n",
    "\n",
    "  # make predictions\n",
    "  predictions = knn_predict(X_test_sample,X_train,Y_train,k=3)\n",
    "\n",
    "  # print test results\n",
    "  print(\"Predictions: \",predictions)\n",
    "  print(\"Actual labels: \",Y_test_sample)\n",
    "\n",
    "  # check if predictions matched expected format\n",
    "  assert predictions.shape == Y_test_sample.shape , \"The shape of predictions does not match the shape of the actual labels\"\n",
    "  print(\"Test case pass successfully.\")\n",
    "\n",
    "except AssertionError as e:\n",
    "  print(\"AssertionError\",e)\n",
    "except Exception as e:\n",
    "  print(\"An unexpected error occurred.\",e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step6 : Computing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN model on the test data is:  57.476635514018696\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(y_true,y_pred):\n",
    "  correct_predictions = np.sum(y_true == y_pred)\n",
    "  total_predictions = len(y_true)\n",
    "  accuracy = (correct_predictions / total_predictions) * 100\n",
    "  return accuracy\n",
    "\n",
    "try:\n",
    "  predictions = knn_predict(X_test,X_train,Y_train,k=3)\n",
    "  accuracy = compute_accuracy(Y_test,predictions)\n",
    "  print (\"Accuracy of KNN model on the test data is: \",accuracy)\n",
    "except Exception as e:\n",
    "  print(\"An unexpected error occurred.\",e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
